const { Logger } = require('./logger');
const OpenAI = require('openai');
const dotenv = require('dotenv');
const { Config } = require('./config');
const chalk = require('chalk');
const fs = require('fs').promises;
const path = require('path');

class AICompletion {
    constructor(client, model, options = {}) {
        this.logger = new Logger('ai');
        const aiConfig = Config.getAIConfig();
            
        // åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        if (client) {
            this.client = client;
            this.model = model;
            console.log(chalk.blue('Using provided AI client:', model));
        } else {
            this.model = aiConfig.model;
            this.client = new OpenAI({
                apiKey: aiConfig.apiKey,
                baseURL: aiConfig.baseUrl
            });
            console.log(chalk.blue('Initialized OpenAI client:', {
                model: this.model,
                baseURL: aiConfig.baseUrl
            }));
        }

        this.options = {
            useLocalSimulation: !this.client,
            ...options
        };

        console.log(chalk.blue('AI completion initialized:', {
            useLocalSimulation: this.options.useLocalSimulation,
            model: this.model
        }));

        // æ·»åŠ æ—¥å¿—è·¯å¾„
        this.logPath = path.resolve(__dirname, '..', 'data', 'ai_logs');
        this.consoleLogPath = path.join(this.logPath, 'console');

        this.systemPrompt = options.systemPrompt || '';
    }

    updateSystemPrompt(newPrompt) {
        this.systemPrompt = newPrompt;
    }

    async _logToConsoleAndFile(level, message, data = {}) {
        // ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—å†…å®¹
        const timestamp = new Date().toISOString();
        const logEntry = {
            timestamp,
            level,
            message,
            data
        };

        // æŽ§åˆ¶å°è¾“å‡ºï¼ˆå¸¦é¢œè‰²ï¼‰
        const colors = {
            info: 'blue',
            success: 'green',
            warning: 'yellow',
            error: 'red'
        };
        console.log(chalk[colors[level] || 'white'](message, data));

        try {
            // ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            await fs.mkdir(this.consoleLogPath, { recursive: true });

            // ç”Ÿæˆæ—¥å¿—æ–‡ä»¶åï¼ˆæŒ‰æ—¥æœŸåˆ†æ–‡ä»¶ï¼‰
            const date = new Date().toISOString().split('T')[0];
            const logFile = path.join(this.consoleLogPath, `console_${date}.log`);

            // è¿½åŠ æ—¥å¿—å†…å®¹
            await fs.appendFile(
                logFile,
                JSON.stringify(logEntry) + '\n',
                'utf8'
            );
        } catch (error) {
            console.error('Error saving console log:', error);
        }
    }

    async getCompletion(systemMessage, userMessage) {
        try {
            if (this.options.useLocalSimulation) {
                return this._getLocalResponse(userMessage);
            }

            const messages = [
                { role: 'system', content: this.systemPrompt || systemMessage },
                { role: 'user', content: userMessage }
            ];

            let result;
            await this._logToConsoleAndFile('info', 'Calling OpenAI API');
            result = await this._getAICompletion(messages);

            await this._logToConsoleAndFile('success', 'Generated content', {
                mode: this.options.useLocalSimulation ? 'local' : 'api',
                tweetsCount: result.length,
                firstTweet: result[0]?.text?.substring(0, 50) + '...'
            });

            return result;
        } catch (error) {
            await this._logToConsoleAndFile('error', 'AI completion failed', error);
            throw error;
        }
    }

    async _getAICompletion(messages) {
        try {
            if (!this.client) {
                await this._logToConsoleAndFile('warning', 'No AI client available, using local simulation');
                return this._getLocalSimulation();
            }

            await this._logToConsoleAndFile('info', 'Making API request', {
                model: this.model,
                systemPrompt: this.systemPrompt?.substring(0, 50) + '...',
                userPrompt: messages[messages.length - 1].content?.substring(0, 50) + '...'
            });

            const response = await this.client.chat.completions.create({
                model: this.model,
                messages: messages
            });

            // ä¿å­˜äº¤äº’è®°å½•
            await this._saveInteraction({
                timestamp: new Date().toISOString(),
                model: this.model,
                systemPrompt: this.systemPrompt,
                userPrompt: messages[messages.length - 1].content,
                response: response.choices[0].message.content,
                success: true
            });

            await this._logToConsoleAndFile('success', 'API response received', {
                status: 'success',
                content: response.choices[0].message.content?.substring(0, 50) + '...'
            });

            const tweets = this._parseAIResponse(response.choices[0].message.content);
            return tweets;
        } catch (error) {
            // ä¿å­˜é”™è¯¯è®°å½•
            await this._saveInteraction({
                timestamp: new Date().toISOString(),
                model: this.model,
                systemPrompt: this.systemPrompt,
                userPrompt: messages[messages.length - 1].content,
                error: error.message,
                success: false
            });

            await this._logToConsoleAndFile('error', 'AI API call failed', {
                error: error.message,
                model: this.model
            });
            await this._logToConsoleAndFile('warning', 'Falling back to local simulation');
            return this._getLocalSimulation();
        }
    }

    async _saveInteraction(data) {
        try {
            // ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            await fs.mkdir(this.logPath, { recursive: true });

            // ç”Ÿæˆæ–‡ä»¶å
            const filename = `ai_interaction_${new Date().toISOString().replace(/[:.]/g, '-')}.json`;
            const filepath = path.join(this.logPath, filename);

            // ä¿å­˜äº¤äº’è®°å½•
            await fs.writeFile(
                filepath,
                JSON.stringify(data, null, 2),
                'utf8'
            );

            console.log(chalk.blue('Interaction log saved:', filepath));
        } catch (error) {
            console.log(chalk.red('Error saving interaction log:', error));
        }
    }

    _getLocalSimulation() {
        console.log(chalk.yellow('Generating local simulation content'));
        
        // æ¨¡æ‹Ÿ AI ç”Ÿæˆ
        const scenes = [
            this._generateScene('å·¥ä½œåœºæ™¯'),
            this._generateScene('ç”Ÿæ´»åœºæ™¯'),
            this._generateScene('ç¤¾äº¤åœºæ™¯')
        ];

        // å°†åœºæ™¯è½¬æ¢ä¸ºæŽ¨æ–‡æ ¼å¼
        const tweets = scenes.flatMap(scene => scene.map((text, index) => ({
            text,
            id: `tweet_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
        })));

        console.log(chalk.green('Local simulation completed:', {
            scenesCount: scenes.length,
            tweetsCount: tweets.length
        }));

        return tweets;
    }

    _generateScene(type) {
        const templates = {
            'å·¥ä½œåœºæ™¯': [
                [
                    "1: å‡Œæ™¨3ç‚¹ï¼Œç¬¬108æ¬¡ä¿®æ”¹ä»£ç ã€‚è¿™ä¸ªbugå¤ªéš¾æ‰¾äº†ï¼Œä½†æˆ‘çŸ¥é“ç­”æ¡ˆå°±åœ¨çœ¼å‰ã€‚æ³¡ä¸€æ¯å’–å•¡ï¼Œç»§ç»­æˆ˜æ–—ã€‚#coding #startup",
                    "2: ç­‰ç­‰ï¼çªç„¶å‘çŽ°ä¸€ä¸ªæœ‰è¶£çš„patternï¼Œå¦‚æžœæŠŠè¿™ä¸ªç®—æ³•æ”¹æˆé€’å½’...æ‰‹æœ‰ç‚¹æŠ–ï¼Œè¿™å¯èƒ½æ˜¯ä¸ªçªç ´å£ï¼",
                    "3: æˆåŠŸäº†ï¼ï¼ï¼é‡æž„åŽæ€§èƒ½æå‡300%ã€‚çœ‹ç€ç»ˆç«¯é‡Œçš„æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼Œè¿™æ„Ÿè§‰æ¯”å–äº†åæ¯å’–å•¡è¿˜è®©äººå…´å¥‹ï¼",
                    "4: æœ‰äººè¯´åˆ›ä¸šæ˜¯åœºé©¬æ‹‰æ¾ï¼Œä½†å¯¹æˆ‘æ¥è¯´ï¼Œæ¯ä¸€ä¸ªè¿™æ ·çš„æ—¶åˆ»éƒ½è®©è¿™æ®µæ—…ç¨‹å€¼å¾—ã€‚æ˜Žå¤©ï¿½ï¿½ï¿½ç»­ï¼Œ$XVIçš„æœªæ¥å°±åœ¨ä»£ç ä¸­ã€‚"
                ]
            ],
            'ç”Ÿæ´»åœºæ™¯': [
                [
                    "1: ä»Šå¤©é‡åˆ°ä¸€ä¸ªè¶…å¯çˆ±çš„åœºæ™¯ï¼æ¥¼ä¸‹å’–å•¡åº—çš„çŒ«å’ªè¶´åœ¨æˆ‘ç¬”è®°æœ¬ä¸Šï¼Œæ­»æ´»ä¸è®©æˆ‘å†™ä»£ç ã€‚ðŸ˜‚ #CatLife",
                    "2: å®ƒå¯¹ç€å±å¹•ä¸Šçš„å…‰æ ‡åˆæŠ“åˆæŒ ï¼Œæžå¾—æˆ‘ç¬‘ä¸å¾—ã€‚æœ€åŽåªèƒ½ä¸€åªæ‰‹æ’¸çŒ«ï¼Œä¸€åªæ‰‹æ•²ä»£ç ã€‚å¤šä»»åŠ¡å¤„ç†èƒ½åŠ›++",
                    "3: ç»“æžœï¼è¿™ä¸ªå°å®¶ä¼™å±…ç„¶å¸®æˆ‘å‘çŽ°äº†ä¸ªbugï¼å®ƒè¸©é”®ç›˜æ—¶è§¦å‘äº†ä¸€ä¸ªè¾¹ç•Œæƒ…å†µã€‚è¯´çŒ«ä¸æ‡‚ç¼–ç¨‹ï¼ŸðŸ˜…",
                    "4: å†³å®šç»™å®ƒå–å\"Debug\"ï¼Œä»¥åŽå°±æ˜¯æˆ‘ä»¬å›¢é˜Ÿçš„é¦–å¸­æµ‹è¯•å–µäº†ã€‚æŠ•èµ„äººè¯´è¦æœ‰å¥½è¿æ°”ï¼Œä¹Ÿè®¸è¿™å°±æ˜¯äº†ï¼ŸðŸ± #StartupLife"
                ]
            ],
            'ç¤¾äº¤åœºæ™¯': [
                [
                    "1: è€å‹èšä¼šï¼Œä»–ä»¬ç¬‘ç§°æˆ‘æ˜¯\"æˆåŠŸäººå£«\"ã€‚å…¶å®žä»–ä»¬ä¸çŸ¥é“ï¼Œæœ€æˆåŠŸçš„æ˜¯è¿™äº›å¹´å‹æƒ…å§‹ç»ˆå¦‚ä¸€ã€‚",
                    "2: è¿˜è®°å¾—å½“å¹´æŒ¤åœ¨å‡ºç§Ÿå±‹å†™ä»£ç ï¼Œå¤§å®¶è½®æµç»™æˆ‘é€é¥­ã€‚çŽ°åœ¨æˆ‘è¯·ä»–ä»¬åƒé¥­ï¼Œä»–ä»¬å´è¯´ï¼š\"èƒ½ä¸èƒ½æ¢å›žé‚£æ—¶çš„ç›’é¥­ï¼Ÿ\"",
                    "3: æœ‹å‹è¯´æˆ‘å˜äº†ï¼Œå˜å¾—æ›´å¿™äº†ã€‚ä½†æœ‰ä¸€ç‚¹æ°¸è¿œä¸ä¼šå˜ï¼Œå°±æ˜¯é‡åˆ°å›°éš¾æ—¶ç¬¬ä¸€ä¸ªæƒ³åˆ°çš„è¿˜æ˜¯ä»–ä»¬ã€‚",
                    "4: çœŸæ­£çš„è´¢å¯Œæ˜¯é‚£äº›åœ¨ä½ è¿˜ä¸€æ— æ‰€æœ‰æ—¶ï¼Œå°±æ„¿æ„é™ªä½ ç–¯ç‹‚çš„äººã€‚#Friendship #æ„Ÿæ©"
                ]
            ]
        };

        return templates[type][0];
    }

    _parseAIResponse(content) {
        try {
            // å°† AI å“åº”æ–‡æœ¬è§£æžä¸ºæŽ¨æ–‡æ•°ç»„
            const tweets = content.split('\n\n')
                .filter(tweet => tweet.trim())
                .map(tweet => ({
                    text: tweet.trim(),
                    id: `tweet_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
                }));
            return tweets;
        } catch (error) {
            this.logger.error('Error parsing AI response', error);
            return this._getLocalSimulation();
        }
    }
}

module.exports = { AICompletion }; 